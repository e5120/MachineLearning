{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用・評価用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def valid(test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = Variable(images, volatile=True)\n",
    "        labels = Variable(labels, volatile=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    val_loss = running_loss / len(test_loader)\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, in_, hidden_, out_):\n",
    "        super(NN, self).__init__()\n",
    "        self.hx = nn.Linear(in_, hidden_)\n",
    "        self.hh = nn.Linear(hidden_, hidden_)\n",
    "        self.hy = nn.Linear(hidden_, out_)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 28 * 28)\n",
    "        out = F.relu(self.hx(out))\n",
    "        out = F.relu(self.hh(out))\n",
    "        out = F.log_softmax(self.hy(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(28*28, 20, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shimazu/research/env/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.6331 val_loss: 0.3191 val_acc: 0.9110\n",
      "epoch 1, loss: 0.2998 val_loss: 0.2722 val_acc: 0.9245\n",
      "epoch 2, loss: 0.2583 val_loss: 0.2547 val_acc: 0.9253\n",
      "epoch 3, loss: 0.2260 val_loss: 0.2130 val_acc: 0.9373\n",
      "epoch 4, loss: 0.2009 val_loss: 0.1954 val_acc: 0.9441\n",
      "epoch 5, loss: 0.1805 val_loss: 0.1713 val_acc: 0.9498\n",
      "epoch 6, loss: 0.1658 val_loss: 0.1611 val_acc: 0.9528\n",
      "epoch 7, loss: 0.1545 val_loss: 0.1566 val_acc: 0.9527\n",
      "epoch 8, loss: 0.1452 val_loss: 0.1519 val_acc: 0.9562\n",
      "epoch 9, loss: 0.1363 val_loss: 0.1429 val_acc: 0.9584\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss = train(train_loader)\n",
    "    val_loss, val_acc = valid(test_loader)\n",
    "\n",
    "    print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n",
    "          % (epoch, loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        self.fc = nn.Linear(7 * 7 * 32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.0384 val_loss: 0.0483 val_acc: 0.9847\n",
      "epoch 1, loss: 0.0307 val_loss: 0.0313 val_acc: 0.9899\n",
      "epoch 2, loss: 0.0244 val_loss: 0.0378 val_acc: 0.9883\n",
      "epoch 3, loss: 0.0220 val_loss: 0.0342 val_acc: 0.9906\n",
      "epoch 4, loss: 0.0178 val_loss: 0.0305 val_acc: 0.9898\n",
      "epoch 5, loss: 0.0145 val_loss: 0.0302 val_acc: 0.9907\n",
      "epoch 6, loss: 0.0118 val_loss: 0.0276 val_acc: 0.9910\n",
      "epoch 7, loss: 0.0115 val_loss: 0.0347 val_acc: 0.9889\n",
      "epoch 8, loss: 0.0093 val_loss: 0.0267 val_acc: 0.9919\n",
      "epoch 9, loss: 0.0079 val_loss: 0.0325 val_acc: 0.9908\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss = train(train_loader)\n",
    "    val_loss, val_acc = valid(test_loader)\n",
    "\n",
    "    print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n",
    "          % (epoch, loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_, hidden_, out_):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_\n",
    "        self.num_layers = 3\n",
    "        self.lstm = nn.LSTM(in_, hidden_, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_, out_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28, 28)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        h0, c0 = Variable(h0), Variable(c0)\n",
    "        out, _ = self.lstm(x, (h0, c0))        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(28, 20, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.1713 val_loss: 0.5409 val_acc: 0.8177\n",
      "epoch 1, loss: 0.4079 val_loss: 0.2980 val_acc: 0.9121\n",
      "epoch 2, loss: 0.2513 val_loss: 0.2036 val_acc: 0.9436\n",
      "epoch 3, loss: 0.1849 val_loss: 0.1684 val_acc: 0.9526\n",
      "epoch 4, loss: 0.1505 val_loss: 0.1501 val_acc: 0.9568\n",
      "epoch 5, loss: 0.1266 val_loss: 0.1073 val_acc: 0.9703\n",
      "epoch 6, loss: 0.1102 val_loss: 0.1178 val_acc: 0.9659\n",
      "epoch 7, loss: 0.0979 val_loss: 0.0945 val_acc: 0.9723\n",
      "epoch 8, loss: 0.0916 val_loss: 0.0919 val_acc: 0.9740\n",
      "epoch 9, loss: 0.0818 val_loss: 0.0828 val_acc: 0.9749\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss = train(train_loader)\n",
    "    val_loss, val_acc = valid(test_loader)\n",
    "\n",
    "    print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n",
    "          % (epoch, loss, val_loss, val_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
